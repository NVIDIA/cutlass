

!memref_smem_f16_ = !cute.memref<f16, smem, align<64>, "(32,16):(1,32)">
module attributes {gpu.container_module} {
  gpu.module @kernels {
    func.func public @kernel_cutlass_kernel_0() attributes {cute.kernel, gpu.kernel, nvvm.reqntid = array<i32: 1, 1, 1>} {
      %smem_ptr = cute_nvgpu.arch.get_dyn_smem() : !cute.ptr<i8, smem, align<1024>> loc(#loc19)
      %int_tuple = cute.make_int_tuple() : () -> !cute.int_tuple<"264"> loc(#loc20)
      %ptr = cute.add_offset(%smem_ptr, %int_tuple) : (!cute.ptr<i8, smem, align<1024>>, !cute.int_tuple<"264">) -> !cute.ptr<i8, smem, align<8>> loc(#loc20)
      %smem_size = cute_nvgpu.arch.get_dyn_smem_size() : i32 loc(#loc21)
      %c264_i32 = arith.constant 264 : i32 loc(#loc5)
      %0 = arith.cmpi sge, %smem_size, %c264_i32 : i32 loc(#loc22)
      cf.assert %0, "Allocation failed: shared memory allocation exceeds available memory set in kernel launch. Allocated bytes: 264 bytes. Please reduce the allocation or set a larger smem size in kernel launch." loc(#loc21)
      %int_tuple_0 = cute.make_int_tuple() : () -> !cute.int_tuple<"0"> loc(#loc23)
      %ptr_1 = cute.add_offset(%smem_ptr, %int_tuple_0) : (!cute.ptr<i8, smem, align<1024>>, !cute.int_tuple<"0">) -> !cute.ptr<i8, smem, align<1024>> loc(#loc23)
      %int_tuple_2 = cute.make_int_tuple() : () -> !cute.int_tuple<"256"> loc(#loc24)
      %ptr_3 = cute.add_offset(%smem_ptr, %int_tuple_2) : (!cute.ptr<i8, smem, align<1024>>, !cute.int_tuple<"256">) -> !cute.ptr<i8, smem, align<256>> loc(#loc24)
      %iter = cute.recast_iter(%ptr_3) : !cute.ptr<i8, smem, align<256>> to !cute.ptr<i32, smem, align<256>> loc(#loc25)
      %int_tuple_4 = cute.make_int_tuple() : () -> !cute.int_tuple<"260"> loc(#loc24)
      %ptr_5 = cute.add_offset(%smem_ptr, %int_tuple_4) : (!cute.ptr<i8, smem, align<1024>>, !cute.int_tuple<"260">) -> !cute.ptr<i8, smem, align<4>> loc(#loc24)
      %iter_6 = cute.recast_iter(%ptr_5) : !cute.ptr<i8, smem, align<4>> to !cute.ptr<i8, smem, align<4>> loc(#loc25)
      %1 = cute.ptrtoint(%ptr) : !cute.ptr<i8, smem, align<8>> to i32 loc(#loc26)
      %c64_i32 = arith.constant 64 : i32 loc(#loc5)
      %2 = arith.addi %1, %c64_i32 : i32 loc(#loc27)
      %c1_i32 = arith.constant 1 : i32 loc(#loc5)
      %3 = arith.subi %2, %c1_i32 : i32 loc(#loc27)
      %c-64_i32 = arith.constant -64 : i32 loc(#loc5)
      %4 = arith.andi %3, %c-64_i32 : i32 loc(#loc27)
      %5 = arith.extsi %4 : i32 to i64 loc(#loc5)
      %iv = cute.assume(%5) : (i64) -> !cute.i64<divby 64> loc(#loc26)
      %6 = cute.inttoptr(%iv) : !cute.i64<divby 64> to !cute.ptr<i8, smem, align<64>> loc(#loc26)
      %int_tuple_7 = cute.make_int_tuple() : () -> !cute.int_tuple<"512"> loc(#loc20)
      %ptr_8 = cute.add_offset(%6, %int_tuple_7) : (!cute.ptr<i8, smem, align<64>>, !cute.int_tuple<"512">) -> !cute.ptr<i8, smem, align<64>> loc(#loc20)
      %smem_size_9 = cute_nvgpu.arch.get_dyn_smem_size() : i32 loc(#loc28)
      %c832_i32 = arith.constant 832 : i32 loc(#loc5)
      %7 = arith.cmpi sge, %smem_size_9, %c832_i32 : i32 loc(#loc22)
      cf.assert %7, "Allocation failed: shared memory allocation exceeds available memory set in kernel launch. Allocated bytes: 832 bytes. Please reduce the allocation or set a larger smem size in kernel launch." loc(#loc28)
      %int_tuple_10 = cute.make_int_tuple() : () -> !cute.int_tuple<"512"> loc(#loc20)
      %ptr_11 = cute.add_offset(%ptr_8, %int_tuple_10) : (!cute.ptr<i8, smem, align<64>>, !cute.int_tuple<"512">) -> !cute.ptr<i8, smem, align<64>> loc(#loc20)
      %smem_size_12 = cute_nvgpu.arch.get_dyn_smem_size() : i32 loc(#loc29)
      %c1344_i32 = arith.constant 1344 : i32 loc(#loc5)
      %8 = arith.cmpi sge, %smem_size_12, %c1344_i32 : i32 loc(#loc22)
      cf.assert %8, "Allocation failed: shared memory allocation exceeds available memory set in kernel launch. Allocated bytes: 1344 bytes. Please reduce the allocation or set a larger smem size in kernel launch." loc(#loc29)
      %iter_13 = cute.recast_iter(%ptr_8) : !cute.ptr<i8, smem, align<64>> to !cute.ptr<i32, smem, align<64>> loc(#loc29)
      %shape = cute.make_shape() : () -> !cute.shape<"(32,16)"> loc(#loc30)
      %lay = cute.make_layout(%shape) : !cute.layout<"(32,16):(1,32)"> loc(#loc30)
      %coord = cute.make_coord() : () -> !cute.coord<"0"> loc(#loc31)
      %idx = cute.crd2idx(%coord, %lay) : (!cute.coord<"0">, !cute.layout<"(32,16):(1,32)">) -> !cute.int_tuple<"0"> loc(#loc31)
      %e0 = cute.get_leaves(%idx) : !cute.int_tuple<"0"> loc(#loc31)
      %cosz = cute.cosize(%lay) : (!cute.layout<"(32,16):(1,32)">) -> !cute.int_tuple<"512"> loc(#loc31)
      %e0_14 = cute.get_leaves(%cosz) : !cute.int_tuple<"512"> loc(#loc31)
      %int_tuple_15 = cute.make_int_tuple() : () -> !cute.int_tuple<"1024"> loc(#loc20)
      %ptr_16 = cute.add_offset(%ptr_11, %int_tuple_15) : (!cute.ptr<i8, smem, align<64>>, !cute.int_tuple<"1024">) -> !cute.ptr<i8, smem, align<64>> loc(#loc20)
      %smem_size_17 = cute_nvgpu.arch.get_dyn_smem_size() : i32 loc(#loc31)
      %c2368_i32 = arith.constant 2368 : i32 loc(#loc5)
      %9 = arith.cmpi sge, %smem_size_17, %c2368_i32 : i32 loc(#loc22)
      cf.assert %9, "Allocation failed: shared memory allocation exceeds available memory set in kernel launch. Allocated bytes: 2368 bytes. Please reduce the allocation or set a larger smem size in kernel launch." loc(#loc31)
      %iter_18 = cute.recast_iter(%ptr_11) : !cute.ptr<i8, smem, align<64>> to !cute.ptr<f16, smem, align<64>> loc(#loc31)
      %view = cute.make_view(%iter_18, %lay) : !memref_smem_f16_ loc(#loc31)
      %iter_19 = cute.get_iter(%view) : !memref_smem_f16_ loc(#loc32)
      return loc(#loc5)
    } loc(#loc18)
  } loc(#loc17)
  func.func @cutlass_launch_kernel1() attributes {llvm.emit_c_interface} {
    %c1 = arith.constant 1 : index loc(#loc5)
    %c2368_i32 = arith.constant 2368 : i32 loc(#loc5)
    gpu.launch_func  @kernels::@kernel_cutlass_kernel_0 blocks in (%c1, %c1, %c1) threads in (%c1, %c1, %c1)  dynamic_shared_memory_size %c2368_i32  {use_pdl = false} loc(#loc18)
    return loc(#loc17)
  } loc(#loc17)
} loc(#loc17)
#loc = loc("/home/jayce.su/notes/dsl/cutlass_with_notes/examples/python/CuTeDSL/ampere/dynamic_smem_size.py":116:4)
#loc1 = loc("/home/jayce.su/notes/dsl/cutlass_with_notes/examples/python/CuTeDSL/ampere/dynamic_smem_size.py":101:4)
#loc2 = loc("/home/jayce.su/notes/dsl/cutlass_with_notes/examples/python/CuTeDSL/ampere/dynamic_smem_size.py":64:16)
#loc3 = loc("/usr/local/lib/python3.12/dist-packages/nvidia_cutlass_dsl/python_packages/cutlass/utils/smem_allocator.py":172:8)
#loc4 = loc("/home/jayce.su/notes/dsl/cutlass_with_notes/examples/python/CuTeDSL/ampere/dynamic_smem_size.py":67:18)
#loc5 = loc(unknown)
#loc6 = loc("/usr/local/lib/python3.12/dist-packages/nvidia_cutlass_dsl/python_packages/cutlass/utils/smem_allocator.py":181:12)
#loc7 = loc("/usr/local/lib/python3.12/dist-packages/nvidia_cutlass_dsl/python_packages/cutlass/cute/core.py":4073:70)
#loc8 = loc("/usr/local/lib/python3.12/dist-packages/nvidia_cutlass_dsl/python_packages/cutlass/cute/core.py":4070:37)
#loc9 = loc("/usr/local/lib/python3.12/dist-packages/nvidia_cutlass_dsl/python_packages/cutlass/cute/core.py":4070:26)
#loc10 = loc("/usr/local/lib/python3.12/dist-packages/nvidia_cutlass_dsl/python_packages/cutlass/utils/smem_allocator.py":170:21)
#loc11 = loc("/usr/local/lib/python3.12/dist-packages/nvidia_cutlass_dsl/python_packages/cutlass/base_dsl/typing.py":846:18)
#loc12 = loc("/home/jayce.su/notes/dsl/cutlass_with_notes/examples/python/CuTeDSL/ampere/dynamic_smem_size.py":68:17)
#loc13 = loc("/home/jayce.su/notes/dsl/cutlass_with_notes/examples/python/CuTeDSL/ampere/dynamic_smem_size.py":69:16)
#loc14 = loc("/home/jayce.su/notes/dsl/cutlass_with_notes/examples/python/CuTeDSL/ampere/dynamic_smem_size.py":72:15)
#loc15 = loc("/home/jayce.su/notes/dsl/cutlass_with_notes/examples/python/CuTeDSL/ampere/dynamic_smem_size.py":70:18)
#loc16 = loc("/usr/local/lib/python3.12/dist-packages/nvidia_cutlass_dsl/python_packages/cutlass/_mlir/dialects/_cute_ops_gen.py":2415:11)
#loc17 = loc("cute.compile(launch_kernel1)"(#loc))
#loc18 = loc("k.launch("(#loc1))
#loc19 = loc("allocator = cutlass.utils.SmemAllocator()"(#loc2))
#loc20 = loc("self._base += size_in_bytes"(#loc3))
#loc21 = loc("shared_data = allocator.allocate(SharedData)"(#loc4))
#loc22 = loc("self._allocated_bytes <= get_dyn_smem_size(loc=loc, ip=ip),"(#loc6))
#loc23 = loc("new_obj = struct._MemRangeData(obj._dtype, obj._size, base + off)"(#loc7))
#loc24 = loc("new_obj = recast_ptr(base + off, dtype=obj)"(#loc8))
#loc25 = loc("new_obj = recast_ptr(base + off, dtype=obj)"(#loc9))
#loc26 = loc("self._base = self._base.align(byte_alignment)"(#loc10))
#loc27 = loc("res_val = op(lhs_val, rhs_val)"(#loc11))
#loc28 = loc("raw_buffer = allocator.allocate(512, byte_alignment=64)"(#loc12))
#loc29 = loc("int_array = allocator.allocate_array(element_type=cutlass.Int32, num_elems=128)"(#loc13))
#loc30 = loc("layout=cute.make_layout((32, 16)),"(#loc14))
#loc31 = loc("tensor_smem = allocator.allocate_tensor("(#loc15))
#loc32 = loc("return self.operation.results[0]"(#loc16))



module attributes {gpu.container_module} {
  gpu.module @kernels {
    func.func public @kernel_cutlass_kernel_no_smem_0() attributes {cute.kernel, gpu.kernel, nvvm.reqntid = array<i32: 1, 1, 1>} {
      %0 = nvvm.read.ptx.sreg.ctaid.x : i32 loc(#loc8)
      %1 = nvvm.read.ptx.sreg.ctaid.y : i32 loc(#loc8)
      %2 = nvvm.read.ptx.sreg.ctaid.z : i32 loc(#loc8)
      %c0_i32 = arith.constant 0 : i32 loc(#loc3)
      %3 = arith.cmpi eq, %0, %c0_i32 : i32 loc(#loc9)
      scf.if %3 {
        cute.print("Hello world\0A", ) :  loc(#loc10)
      } loc(#loc3)
      return loc(#loc3)
    } loc(#loc7)
  } loc(#loc6)
  func.func @cutlass_launch_kernel2() attributes {llvm.emit_c_interface} {
    %c1 = arith.constant 1 : index loc(#loc3)
    %c0_i32 = arith.constant 0 : i32 loc(#loc3)
    gpu.launch_func  @kernels::@kernel_cutlass_kernel_no_smem_0 blocks in (%c1, %c1, %c1) threads in (%c1, %c1, %c1)  dynamic_shared_memory_size %c0_i32  {use_pdl = false} loc(#loc7)
    return loc(#loc6)
  } loc(#loc6)
} loc(#loc6)
#loc = loc("/home/jayce.su/notes/dsl/cutlass_with_notes/examples/python/CuTeDSL/ampere/dynamic_smem_size.py":117:4)
#loc1 = loc("/home/jayce.su/notes/dsl/cutlass_with_notes/examples/python/CuTeDSL/ampere/dynamic_smem_size.py":110:4)
#loc2 = loc("/home/jayce.su/notes/dsl/cutlass_with_notes/examples/python/CuTeDSL/ampere/dynamic_smem_size.py":85:17)
#loc3 = loc(unknown)
#loc4 = loc("/usr/local/lib/python3.12/dist-packages/nvidia_cutlass_dsl/python_packages/cutlass/base_dsl/typing.py":846:18)
#loc5 = loc("/home/jayce.su/notes/dsl/cutlass_with_notes/examples/python/CuTeDSL/ampere/dynamic_smem_size.py":87:8)
#loc6 = loc("cute.compile(launch_kernel2)"(#loc))
#loc7 = loc("k.launch("(#loc1))
#loc8 = loc("tidx, _, _ = cute.arch.block_idx()"(#loc2))
#loc9 = loc("res_val = op(lhs_val, rhs_val)"(#loc4))
#loc10 = loc("cute.printf(\22Hello world\22)"(#loc5))

